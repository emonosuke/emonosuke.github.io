<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>emonosuke</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-KK94CHFLLe+nY2dmCWGMq91rCGa5gtU4mk92HdvYe+M/SXH301p5ILy+dN9+nJOZ" crossorigin="anonymous">
    <link rel="stylesheet" href="custom.css">
  </head>
  <body>
    <nav class="navbar navbar-light bg-light">
    <div class="container-fluid">
        <span class="navbar-brand"><h3>About me<h3></span>
    </div>
    </nav>
    <div class="container">
        <div class="container">
        <p class="fw-bold">Hayato Futami</p>
        <ul>
            <li>2016.4-2020.3 Kyoto University</li>
            <li>2020.4-2022.3 Kyoto University, Graduate School of Informatics</li>
                <ul><li>Speech and Audio Processing Lab. (Supervisor: Prof. Tatsuya Kawahara)</li></ul>
            <li>2022.4- Sony Group Corporation, Speech and Language AI Lab., Research engineer</li>
        </ul>
        <p>[<a href="https://www.linkedin.com/in/hayato-futami-7205a41b0/">LinkedIn</a>] [<a href="https://github.com/emonosuke">GitHub</a>] [<a href="https://twitter.com/emonosuke">Twitter</a>]</p>
        </div>
        <div class="container"><h4 class="fw-bold">Publications (1st author)</h4>
            <ul>
                <li>"The Pipeline System of ASR and NLU with MLM-based Data Augmentation toward STOP Low-resource Challenge"
                    [<a href="https://arxiv.org/abs/2305.01194">link</a>], ICASSP2023 <i class="text-muted">(Won 1st place at SLU Grand Challenge)</i></li>
                <li>"Streaming Joint Speech Recognition and Disfluency Detection"
                    [<a href="https://arxiv.org/abs/2211.08726">link</a>], ICASSP2023</li>
                <li>"Non-autoregressive Error Correction for CTC-based ASR with Phone-conditioned Masked LM"
                    [<a href="https://arxiv.org/abs/2209.04062">link</a>], Interspeech2022</li>
                <li>"Distilling the Knowledge of BERT for CTC-based ASR"
                    [<a href="https://arxiv.org/abs/2209.02030">link</a>], 2021</li>
                <li>"ASR Rescoring and Confidence Estimation with ELECTRA"
                    [<a href="https://arxiv.org/abs/2110.01857">link</a>], ASRU2021</li>
                <li>"Distilling the Knowledge of BERT for Sequence-to-Sequence ASR"
                    [<a href="https://arxiv.org/abs/2008.03822">link</a>], Interspeech2020 <i class="text-muted">(Nominated for ISCA Best student award)</i></li>
            </ul>
        </div>
        <div class="container"><h4 class="fw-bold">Awards</h4>
        <ul>
            <li>ASJ, Student Award, 2021 [<a href="https://acoustics.jp/awards/student">link</a>]</li>
            <li>IPSJ Yamashita SIG Research Award, 2021 [<a href="https://www.ipsj.or.jp/award/yamashita2021.html">link</a>]</li>
            <li>SIG-SLP, Yahoo! Japan Award, 2020 [<a href="https://www.ipsj.or.jp/award/slp-award2.html">link</a>]</li>
            <li>IPSJ National Convention, Best Paper Award, 2020 [<a href="http://www.ipsj.or.jp/award/taikaiyusyu.html">link</a>]</li>
            <li>IPSJ National Convention, Student Encouragement Award, 2020 [<a href="http://www.ipsj.or.jp/award/taikaigakusei.html">link</a>]</li>
        </ul>
        </div>
        <div class="container"><h4 class="fw-bold">Work Experiences</h4>
        <ul>
            <li>Patentfield (2021-2022), ML engineer (NLP)</li>
            <li>Hacarus (2018-2020), ML engineer (Image diagnosis)</li>
            <li>CO-CONV (2017-2018), Software engineer (Visual C++)</li>
            <li>DeNA (2021.8), Text-to-speech</li>
            <li>LINE (2019.8)</li>
            <li>Yahoo Japan (2019.3)</li>
        </ul>
        </div>
    </div>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ENjdO4Dr2bkBIFxQpeoTz1HIcje39Wm4jDKdf19U8gI4ddQ3GYNS7NTKfAdVQSZe" crossorigin="anonymous"></script>
  </body>
</html>
